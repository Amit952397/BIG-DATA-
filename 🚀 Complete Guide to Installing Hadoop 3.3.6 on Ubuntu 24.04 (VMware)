üöÄ Complete Guide to Installing Hadoop 3.3.6 on Ubuntu 24.04 (VMware)
üìò Overview

This guide helps you install and configure Hadoop 3.3.6 in pseudo-distributed mode on Ubuntu 24.04 running inside VMware.
It includes SSH setup, Java configuration, environment variables, troubleshooting, and verification steps.

üß© 1Ô∏è‚É£ Prerequisites

Ensure the following before you begin:

‚úî Ubuntu 24.04 running in VMware Workstation
‚úî At least 4 GB RAM, 50 GB disk space, and 4 CPU cores
‚úî Java 8 (JDK 1.8.0_368) installed at:

/home/amitkumar/Downloads/jdk1.8.0_368/

üß≠ 2Ô∏è‚É£ Update Ubuntu Packages

Keep your system up to date:

sudo apt update && sudo apt upgrade -y

‚òï 3Ô∏è‚É£ Verify Java Installation

You‚Äôve already installed Java 8 manually. Let‚Äôs confirm it:

java -version


Expected output:

java version "1.8.0_368"
Java(TM) SE Runtime Environment (build 1.8.0_368-bXX)
Java HotSpot(TM) 64-Bit Server VM


If not, set JAVA_HOME globally:

sudo nano /etc/environment


Add this line:

JAVA_HOME="/home/amitkumar/Downloads/jdk1.8.0_368/"


Then reload:

source /etc/environment


Check:

echo $JAVA_HOME

üßë‚Äçüíª 4Ô∏è‚É£ (Optional) Create Hadoop User

For better security, create a separate user:

sudo adduser hadoop
sudo usermod -aG sudo hadoop
su - hadoop


If you prefer, continue as your current user (amitkumar).

üì¶ 5Ô∏è‚É£ Download & Install Hadoop 3.3.6

Download Hadoop:

wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz


Extract:

tar -xvzf hadoop-3.3.6.tar.gz


Move to installation directory:

sudo mv hadoop-3.3.6 /usr/local/hadoop


Set ownership:

sudo chown -R $USER:$USER /usr/local/hadoop

‚öôÔ∏è 6Ô∏è‚É£ Set Hadoop Environment Variables

Edit .bashrc:

nano ~/.bashrc


Add at the end:

# Hadoop Environment Variables
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export JAVA_HOME=/home/amitkumar/Downloads/jdk1.8.0_368/
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin


Apply:

source ~/.bashrc


Verify:

echo $HADOOP_HOME


Expected output:

/usr/local/hadoop

üß© 7Ô∏è‚É£ Configure Hadoop Core Files
(a) hadoop-env.sh
nano $HADOOP_HOME/etc/hadoop/hadoop-env.sh


Find:

export JAVA_HOME=


Replace with:

export JAVA_HOME=/home/amitkumar/Downloads/jdk1.8.0_368/

(b) core-site.xml
nano $HADOOP_HOME/etc/hadoop/core-site.xml


Replace with:

<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>

(c) hdfs-site.xml
nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml


Add:

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.name.dir</name>
        <value>file:///usr/local/hadoop/hdfs/namenode</value>
    </property>
    <property>
        <name>dfs.data.dir</name>
        <value>file:///usr/local/hadoop/hdfs/datanode</value>
    </property>
</configuration>


Create directories:

mkdir -p /usr/local/hadoop/hdfs/namenode
mkdir -p /usr/local/hadoop/hdfs/datanode
sudo chown -R $USER:$USER /usr/local/hadoop/hdfs

(d) mapred-site.xml
cp $HADOOP_HOME/etc/hadoop/mapred-site.xml.template $HADOOP_HOME/etc/hadoop/mapred-site.xml
nano $HADOOP_HOME/etc/hadoop/mapred-site.xml


Add:

<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
    </property>
</configuration>

(e) yarn-site.xml
nano $HADOOP_HOME/etc/hadoop/yarn-site.xml


Add:

<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>

üîê 8Ô∏è‚É£ Configure Passwordless SSH
sudo apt install ssh -y
ssh-keygen -t rsa -P ""
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
ssh localhost


If you can log in without a password ‚Üí ‚úÖ success.

üß± 9Ô∏è‚É£ Format Namenode & Start Hadoop
Format the HDFS:
hdfs namenode -format

Start HDFS:
start-dfs.sh

Start YARN:
start-yarn.sh

Verify Processes:
jps


Expected output:

NameNode
DataNode
ResourceManager
NodeManager

‚úÖ üîü Verify Installation in Browser

üìÇ HDFS Web UI:
üëâ http://localhost:9870/

üßÆ YARN ResourceManager:
üëâ http://localhost:8088/

üß© 11Ô∏è‚É£ Troubleshooting Tips
Problem	Cause	Fix
NameNode not starting	Wrong JAVA_HOME	Verify hadoop-env.sh path
ssh: connect to host localhost port 22	SSH not installed	Run sudo apt install ssh
Permission denied	Wrong file ownership	sudo chown -R $USER:$USER /usr/local/hadoop
DataNode refused connection	Ports conflict	Stop and restart all Hadoop daemons

üéâ Congratulations, Amit!
You have successfully installed and configured Hadoop 3.3.6 on Ubuntu 24.04 (VMware) using your custom JDK 1.8.0_368 setup.
Your single-node pseudo-distributed Hadoop system is ready for use with HDFS, YARN, and MapReduce.
